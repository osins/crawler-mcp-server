#!/usr/bin/env python3

import asyncio
import tempfile
import os
import shutil
from spider_mcp_server.server import handle_call_tool, TextContent

def clean_temp_dir(temp_dir):
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)
        print(f"\nğŸ§¹ å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
        
async def test_complete_crawler():
    print("ğŸ” æµ‹è¯•å®Œæ•´çš„çˆ¬è™«åŠŸèƒ½ï¼ˆåŒ…å«æ–‡ä»¶ä¿å­˜ï¼‰")
    print("=" * 50)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = "./test_output/complete_crawler_test"
    
    clean_temp_dir(temp_dir)

    os.makedirs(temp_dir, exist_ok=True)
    
    try:
        print(f"ğŸ“ æµ‹è¯•ç›®å½•: {temp_dir}")
        
        # æµ‹è¯•çˆ¬è™«è°ƒç”¨
        result = await handle_call_tool("crawl_web_page", {
            "url": "https://zh.wikipedia.org/zh-cn/%E7%8E%89%E8%92%B2%E5%9C%98%E4%B9%8B%E5%81%B7%E6%83%85%E5%AF%B6%E9%91%91",
            "save_path": temp_dir
        })
        
        print("ğŸ“¤ çˆ¬è™«æ‰§è¡Œç»“æœ:")
        for content in result:
            if hasattr(content, 'text'):
                print(f"   {content.text}")
        
        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        print(f"\nğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
        if os.path.exists(temp_dir):
            files = os.listdir(temp_dir)
            for file in sorted(files):
                file_path = os.path.join(temp_dir, file)
                if os.path.isfile(file_path):
                    size = os.path.getsize(file_path)
                    print(f"   âœ… {file} ({size} bytes)")
                elif os.path.isdir(file_path):
                    sub_files = os.listdir(file_path)
                    print(f"   ğŸ“ {file}/ ç›®å½• ({len(sub_files)} ä¸ªæ–‡ä»¶)")
                    for sub_file in sorted(sub_files):
                        sub_path = os.path.join(file_path, sub_file)
                        sub_size = os.path.getsize(sub_path)
                        print(f"      ğŸ“„ {sub_file} ({sub_size} bytes)")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_complete_crawler())